Best model so far. 
Training Model with learning rate 2.0e-4 and activation function of eLU
20000/20000 [==============================] - 135s - loss: 0.0407 - val_loss: 0.0233
Epoch 2/10
20000/20000 [==============================] - 114s - loss: 0.0381 - val_loss: 0.0221
Epoch 3/10
20000/20000 [==============================] - 111s - loss: 0.0366 - val_loss: 0.0228
Epoch 4/10
20000/20000 [==============================] - 112s - loss: 0.0335 - val_loss: 0.0238
Epoch 5/10
20000/20000 [==============================] - 111s - loss: 0.0320 - val_loss: 0.0255
Epoch 6/10
20000/20000 [==============================] - 111s - loss: 0.0305 - val_loss: 0.0234
Epoch 7/10
20000/20000 [==============================] - 111s - loss: 0.0294 - val_loss: 0.0238
Epoch 8/10
20000/20000 [==============================] - 112s - loss: 0.0288 - val_loss: 0.0230
Epoch 9/10
20000/20000 [==============================] - 112s - loss: 0.0287 - val_loss: 0.0172
Epoch 10/10
20000/20000 [==============================] - 112s - loss: 0.0262 - val_loss: 0.0182

Training Model with learning rate 1.0e-3 and activation function of eLU
20000/20000 [==============================] - 109s - loss: 0.0423 - val_loss: 0.0251
Epoch 2/10
20000/20000 [==============================] - 109s - loss: 0.0389 - val_loss: 0.0252
Epoch 3/10
20000/20000 [==============================] - 109s - loss: 0.0387 - val_loss: 0.0306
Epoch 4/10
20000/20000 [==============================] - 109s - loss: 0.0455 - val_loss: 0.0387
Epoch 5/10
20000/20000 [==============================] - 109s - loss: 0.0463 - val_loss: 0.0297
Epoch 6/10
20000/20000 [==============================] - 109s - loss: 0.0459 - val_loss: 0.0305
Epoch 7/10
20000/20000 [==============================] - 109s - loss: 0.0476 - val_loss: 0.0398
Epoch 8/10
20000/20000 [==============================] - 109s - loss: 0.0480 - val_loss: 0.0320
Epoch 9/10
20000/20000 [==============================] - 109s - loss: 0.0472 - val_loss: 0.0214
Epoch 10/10
20000/20000 [==============================] - 109s - loss: 0.0477 - val_loss: 0.0391

Training Model with learning rate 5.0e-4 and activation function of eLU
20000/20000 [==============================] - 110s - loss: 0.1332 - val_loss: 0.0357
Epoch 2/10
20000/20000 [==============================] - 111s - loss: 0.0469 - val_loss: 0.0286
Epoch 3/10
20000/20000 [==============================] - 112s - loss: 0.0478 - val_loss: 0.0363
Epoch 4/10
20000/20000 [==============================] - 112s - loss: 0.0457 - val_loss: 0.0396
Epoch 5/10
20000/20000 [==============================] - 180s - loss: 0.0464 - val_loss: 0.0292
Epoch 6/10
20000/20000 [==============================] - 110s - loss: 0.0462 - val_loss: 0.0292
Epoch 7/10
20000/20000 [==============================] - 110s - loss: 0.0479 - val_loss: 0.0317
Epoch 8/10
20000/20000 [==============================] - 110s - loss: 0.0483 - val_loss: 0.0322
Epoch 9/10
20000/20000 [==============================] - 110s - loss: 0.0480 - val_loss: 0.0228
Epoch 10/10
20000/20000 [==============================] - 111s - loss: 0.0478 - val_loss: 0.0274

Training Model with learning rate 2.0e-4 on 5 sets of training data and activation function of eLU
20000/20000 [==============================] - 168s - loss: 0.0357 - val_loss: 0.0174
Epoch 2/10
20000/20000 [==============================] - 128s - loss: 0.0336 - val_loss: 0.0186
Epoch 3/10
20000/20000 [==============================] - 119s - loss: 0.0334 - val_loss: 0.0182
Epoch 4/10
20000/20000 [==============================] - 117s - loss: 0.0315 - val_loss: 0.0160
Epoch 5/10
20000/20000 [==============================] - 116s - loss: 0.0310 - val_loss: 0.0154
Epoch 6/10
20000/20000 [==============================] - 115s - loss: 0.0292 - val_loss: 0.0195
Epoch 7/10
20000/20000 [==============================] - 116s - loss: 0.0292 - val_loss: 0.0132
Epoch 8/10
20000/20000 [==============================] - 117s - loss: 0.0283 - val_loss: 0.0171
Epoch 9/10
20000/20000 [==============================] - 117s - loss: 0.0277 - val_loss: 0.0148
Epoch 10/10
20000/20000 [==============================] - 117s - loss: 0.0269 - val_loss: 0.0165

Same configuration as above but I am comparing the performance of all the models 
20000/20000 [==============================] - 118s - loss: 0.0357 - val_loss: 0.0169
Epoch 2/10
20000/20000 [==============================] - 117s - loss: 0.0336 - val_loss: 0.0194
Epoch 3/10
20000/20000 [==============================] - 116s - loss: 0.0332 - val_loss: 0.0205
Epoch 4/10
20000/20000 [==============================] - 117s - loss: 0.0313 - val_loss: 0.0134
Epoch 5/10
20000/20000 [==============================] - 117s - loss: 0.0305 - val_loss: 0.0147
Epoch 6/10
20000/20000 [==============================] - 117s - loss: 0.0292 - val_loss: 0.0176
Epoch 7/10
20000/20000 [==============================] - 117s - loss: 0.0293 - val_loss: 0.0147
Epoch 8/10
20000/20000 [==============================] - 117s - loss: 0.0293 - val_loss: 0.0145
Epoch 9/10
20000/20000 [==============================] - 117s - loss: 0.0281 - val_loss: 0.0143
Epoch 10/10
20000/20000 [==============================] - 118s - loss: 0.0278 - val_loss: 0.0172

Model with 2 laps of training data and learning rate of 1.5e-4 and activation function of eLU
20000/20000 [==============================] - 117s - loss: 0.0408 - val_loss: 0.0226
Epoch 2/30
20000/20000 [==============================] - 114s - loss: 0.0381 - val_loss: 0.0215
Epoch 3/30
20000/20000 [==============================] - 114s - loss: 0.0371 - val_loss: 0.0250
Epoch 4/30
20000/20000 [==============================] - 113s - loss: 0.0339 - val_loss: 0.0238
Epoch 5/30
20000/20000 [==============================] - 114s - loss: 0.0325 - val_loss: 0.0263
Epoch 6/30
20000/20000 [==============================] - 113s - loss: 0.0312 - val_loss: 0.0260
Epoch 7/30
20000/20000 [==============================] - 113s - loss: 0.0308 - val_loss: 0.0262
Epoch 8/30
20000/20000 [==============================] - 113s - loss: 0.0297 - val_loss: 0.0197
Epoch 9/30
20000/20000 [==============================] - 113s - loss: 0.0299 - val_loss: 0.0233
Epoch 10/30
20000/20000 [==============================] - 113s - loss: 0.0273 - val_loss: 0.0208
Epoch 11/30
20000/20000 [==============================] - 113s - loss: 0.0269 - val_loss: 0.0233
Epoch 12/30
20000/20000 [==============================] - 114s - loss: 0.0261 - val_loss: 0.0211
Epoch 13/30
20000/20000 [==============================] - 113s - loss: 0.0253 - val_loss: 0.0225
Epoch 14/30
20000/20000 [==============================] - 114s - loss: 0.0251 - val_loss: 0.0301
Epoch0 15/30
20000/20000 [==============================] - 113s - loss: 0.0247 - val_loss: 0.0215
Epoch 16/30
20000/20000 [==============================] - 113s - loss: 0.0239 - val_loss: 0.0190
Epoch 17/30
20000/20000 [==============================] - 114s - loss: 0.0241 - val_loss: 0.0226
Epoch 18/30
20000/20000 [==============================] - 114s - loss: 0.0238 - val_loss: 0.0259
Epoch 19/30
20000/20000 [==============================] - 113s - loss: 0.0228 - val_loss: 0.0252
Epoch 20/30
20000/20000 [==============================] - 114s - loss: 0.0226 - val_loss: 0.0253
Epoch 21/30
20000/20000 [==============================] - 114s - loss: 0.0225 - val_loss: 0.0275
Epoch 22/30
20000/20000 [==============================] - 62339s - loss: 0.0226 - val_loss: 0.0248
Epoch 23/30
20000/20000 [==============================] - 109s - loss: 0.0226 - val_loss: 0.0282
Epoch 24/30
20000/20000 [==============================] - 113s - loss: 0.0225 - val_loss: 0.0252
Epoch 25/30
20000/20000 [==============================] - 111s - loss: 0.0215 - val_loss: 0.0201
Epoch 26/30
20000/20000 [==============================] - 110s - loss: 0.0216 - val_loss: 0.0219
Epoch 27/30
20000/20000 [==============================] - 111s - loss: 0.0215 - val_loss: 0.0266
Epoch 28/30
20000/20000 [==============================] - 111s - loss: 0.0218 - val_loss: 0.0225
Epoch 29/30
20000/20000 [==============================] - 111s - loss: 0.0214 - val_loss: 0.0210
Epoch 30/30
20000/20000 [==============================] - 110s - loss: 0.0208 - val_loss: 0.0239

Model(model-V1.08) with 2 laps of training data and learning rate of 2.0e-4 and activation function of ReLU
20000/20000 [==============================] - 114s - loss: 0.0398 - val_loss: 0.0195
Epoch 2/10
20000/20000 [==============================] - 111s - loss: 0.0332 - val_loss: 0.0185
Epoch 3/10
20000/20000 [==============================] - 114s - loss: 0.0319 - val_loss: 0.0228
Epoch 4/10
20000/20000 [==============================] - 112s - loss: 0.0290 - val_loss: 0.0207
Epoch 5/10
20000/20000 [==============================] - 111s - loss: 0.0279 - val_loss: 0.0186
Epoch 6/10
20000/20000 [==============================] - 111s - loss: 0.0259 - val_loss: 0.0207
Epoch 7/10
20000/20000 [==============================] - 112s - loss: 0.0255 - val_loss: 0.0260
Epoch 8/10
20000/20000 [==============================] - 112s - loss: 0.0248 - val_loss: 0.0211
Epoch 9/10
20000/20000 [==============================] - 113s - loss: 0.0246 - val_loss: 0.0209
Epoch 10/10
20000/20000 [==============================] - 112s - loss: 0.0227 - val_loss: 0.0277 

Model(model-V1.09) with 2 laps of training data and learning rate of 2.0e-4 and activation function of eLU and Loss function of mean_absolute_error
20000/20000 [==============================] - 114s - loss: 0.1351 - val_loss: 0.0795
Epoch 2/10
20000/20000 [==============================] - 113s - loss: 0.1314 - val_loss: 0.0842
Epoch 3/10
20000/20000 [==============================] - 113s - loss: 0.1301 - val_loss: 0.0881
Epoch 4/10 
20000/20000 [==============================] - 111s - loss: 0.1260 - val_loss: 0.0901
Epoch 5/10
20000/20000 [==============================] - 110s - loss: 0.1238 - val_loss: 0.0762
Epoch 6/10
20000/20000 [==============================] - 115s - loss: 0.1206 - val_loss: 0.0855
Epoch 7/10
20000/20000 [==============================] - 115s - loss: 0.1196 - val_loss: 0.0855
Epoch 8/10
20000/20000 [==============================] - 115s - loss: 0.1168 - val_loss: 0.0787
Epoch 9/10
20000/20000 [==============================] - 115s - loss: 0.1141 - val_loss: 0.0830
Epoch 10/10
20000/20000 [==============================] - 116s - loss: 0.1106 - val_loss: 0.0631

Model(model-V1.10) with 2 laps of training data and learning rate of 2.0e-4 and activation function of ReLU and Loss function of mean_squared_error. Using Drop out after each layer
20000/20000 [==============================] - 126s - loss: 0.0460 - val_loss: 0.0254
Epoch 2/10
20000/20000 [==============================] - 126s - loss: 0.0468 - val_loss: 0.0281
Epoch 3/10
20000/20000 [==============================] - 123s - loss: 0.0476 - val_loss: 0.0283
Epoch 4/10
20000/20000 [==============================] - 120s - loss: 0.0453 - val_loss: 0.0351
Epoch 5/10
20000/20000 [==============================] - 123s - loss: 0.0463 - val_loss: 0.0319
Epoch 6/10
20000/20000 [==============================] - 124s - loss: 0.0461 - val_loss: 0.0276
Epoch 7/10
20000/20000 [==============================] - 127s - loss: 0.0475 - val_loss: 0.0356
Epoch 8/10
20000/20000 [==============================] - 128s - loss: 0.0477 - val_loss: 0.0297
Epoch 9/10
20000/20000 [==============================] - 126s - loss: 0.0472 - val_loss: 0.0296
Epoch 10/10
20000/20000 [==============================] - 128s - loss: 0.0476 - val_loss: 0.0309


Model(model-V1.11) with 2 laps of training data and learning rate of 2.0e-4 and activation function of ReLU and Loss function of mean_squared_error. Not using Dropout
20000/20000 [==============================] - 127s - loss: 0.0417 - val_loss: 0.0215
Epoch 2/10
20000/20000 [==============================] - 124s - loss: 0.0356 - val_loss: 0.0189
Epoch 3/10
20000/20000 [==============================] - 121s - loss: 0.0333 - val_loss: 0.0178
Epoch 4/10
20000/20000 [==============================] - 121s - loss: 0.0291 - val_loss: 0.0220
Epoch 5/10
20000/20000 [==============================] - 124s - loss: 0.0280 - val_loss: 0.0209
Epoch 6/10
20000/20000 [==============================] - 129s - loss: 0.0267 - val_loss: 0.0215
Epoch 7/10
20000/20000 [==============================] - 122s - loss: 0.0271 - val_loss: 0.0241
Epoch 8/10
20000/20000 [==============================] - 122s - loss: 0.0264 - val_loss: 0.0227
Epoch 9/10
20000/20000 [==============================] - 134s - loss: 0.0261 - val_loss: 0.0184
Epoch 10/10
20000/20000 [==============================] - 125s - loss: 0.0249 - val_loss: 0.0275

Model(model-V1.13) with 2 laps of training data and learning rate of 2.0e-4 and activation function of ReLU and Loss function of mean_squared_error. Using drop out after evey layer of 20%
20000/20000 [==============================] - 117s - loss: 0.0415 - val_loss: 0.0221
Epoch 2/10
20000/20000 [==============================] - 125s - loss: 0.0355 - val_loss: 0.0192
Epoch 3/10
20000/20000 [==============================] - 123s - loss: 0.0333 - val_loss: 0.0220
Epoch 4/10
20000/20000 [==============================] - 122s - loss: 0.0293 - val_loss: 0.0232
Epoch 5/10
20000/20000 [==============================] - 123s - loss: 0.0284 - val_loss: 0.0225
Epoch 6/10
20000/20000 [==============================] - 123s - loss: 0.0270 - val_loss: 0.0204
Epoch 7/10
20000/20000 [==============================] - 123s - loss: 0.0270 - val_loss: 0.0289
Epoch 8/10
20000/20000 [==============================] - 123s - loss: 0.0263 - val_loss: 0.0260
Epoch 9/10
20000/20000 [==============================] - 124s - loss: 0.0258 - val_loss: 0.0243
Epoch 10/10
20000/20000 [==============================] - 119s - loss: 0.0246 - val_loss: 0.0207
